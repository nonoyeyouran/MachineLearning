# 粗排模型综述

## 目录
1. [粗排的作用](#1-粗排的作用)
2. [粗排的设计原则](#2-粗排的设计原则)
3. [粗排的常用模型](#3-粗排的常用模型)
   - [基于规则的排序模型](#31-基于规则的排序模型)
   - [逻辑回归（Logistic Regression, LR）](#32-逻辑回归logistic-regression-lr)
   - [梯度提升决策树（GBDT）](#33-梯度提升决策树gbdt)
   - [浅层神经网络（Shallow DNN）](#34-浅层神经网络shallow-dnn)
   - [向量相似度排序](#35-向量相似度排序)
   - [简化的排序学习（Learning to Rank, LTR）](#36-简化的排序学习learning-to-rank-ltr)
4. [粗排的最新进展](#4-粗排的最新进展)
   - [轻量化深度模型的优化](#41-轻量化深度模型的优化)
   - [多任务学习（Multi-task Learning）](#42-多任务学习multi-task-learning)
   - [基于预计算的加速](#43-基于预计算的加速)
   - [自适应粗排](#44-自适应粗排)
   - [结合大语言模型（LLM）的粗排](#45-结合大语言模型llm的粗排)
   - [多样性与公平性优化](#46-多样性与公平性优化)
5. [总结](#5-总结)
   - [常用模型总结](#51-常用模型总结)
   - [最新进展总结](#52-最新进展总结)

---

## 1. 粗排的作用
粗排（Coarse Ranking）是推荐系统中介于召回和精排之间的可选阶段，其主要作用包括：
- **效率与效果的平衡**：快速剔除不相关候选项，保留高质量内容。
- **降低计算成本**：减少精排的候选集规模，提升系统性能。
- **过渡筛选**：比召回更精准，比精排更高效，起到承上启下的作用。

---

## 2. 粗排的设计原则
- **轻量化**：采用低复杂度算法，保证快速运行。
- **高召回率**：避免漏掉优质内容，优先保证覆盖率。
- **可扩展性**：适应候选集规模的变化。
- **与精排协同**：排序逻辑尽量与精排一致。

---

## 3. 粗排的常用模型

### 3.1 基于规则的排序模型
- **描述**：通过预定义规则或简单评分函数打分。
- **实现方式**：
  - 加权求和：`Score = w1 * Popularity + w2 * Freshness + w3 * UserMatch`
  - 规则过滤：如“过去24小时点击率高于阈值”。
- **优点**：简单高效，无需训练。
- **缺点**：缺乏个性化。
- **适用场景**：小型系统或baseline。

### 3.2 逻辑回归（Logistic Regression, LR）
- **描述**：将推荐任务转为二分类问题，预测点击概率。
- **特征**：用户画像、物品属性、简单交叉特征。
- **优点**：轻量高效，适合实时预测。
- **缺点**：线性模型，表达能力有限。
- **适用场景**：资源敏感场景。

### 3.3 梯度提升决策树（GBDT）
- **描述**：基于树模型的集成学习，如XGBoost、LightGBM。
- **特征**：稀疏特征（用户行为）、连续特征（点击率）。
- **优点**：效果好，开销可控。
- **缺点**：特征交互能力稍弱。
- **适用场景**：中等规模系统。

### 3.4 浅层神经网络（Shallow DNN）
- **描述**：1-2层隐藏层的神经网络，结合Embedding预测相关性。
- **特征**：预训练Embedding、上下文信息。
- **优点**：捕捉非线性关系，个性化强。
- **缺点**：计算成本略高。
- **适用场景**：YouTube等经典粗排方法。

### 3.5 向量相似度排序
- **描述**：用预训练Embedding计算用户与物品的相似度。
- **实现方式**：协同过滤、矩阵分解、ANN加速。
- **优点**：个性化强，推理快。
- **缺点**：依赖Embedding质量。
- **适用场景**：内容推荐（如新闻、视频）。

### 3.6 简化的排序学习（Learning to Rank, LTR）
- **描述**：采用Pairwise或Pointwise方法优化排序。
- **特征**：与LR或GBDT类似，注重排序指标。
- **优点**：直接优化排序效果。
- **缺点**：复杂度稍高。
- **适用场景**：排序质量要求高的场景。

---

## 4. 粗排的最新进展

### 4.1 轻量化深度模型的优化
- **趋势**：深度学习技术优化效率。
- **进展**：
  - **Mobile-friendly DNN**：减少参数和计算量。
  - **知识蒸馏**：用精排模型训练轻量粗排模型。
- **案例**：字节跳动使用蒸馏后的浅层DNN。

### 4.2 多任务学习（Multi-task Learning）
- **趋势**：联合优化多个目标。
- **进展**：
  - **MMOE**：同时预测CTR、CVR等。
  - **动态权重**：根据实时行为调整任务权重。
- **优势**：贴近业务需求。

### 4.3 基于预计算的加速
- **趋势**：离线预计算减少在线负担。
- **进展**：
  - **两阶段Embedding**：离线生成GNN嵌入，在线计算相似度。
  - **候选池预筛选**：提前生成热门池。
- **案例**：淘宝结合预计算提升性能。

### 4.4 自适应粗排
- **趋势**：动态调整粗排策略。
- **进展**：
  - **分层粗排**：根据候选集规模选择策略。
  - **在线学习**：实时更新参数。
- **优势**：适合动态场景。

### 4.5 结合大语言模型（LLM）的粗排
- **趋势**：利用LLM提升语义理解。
- **进展**：
  - **文本特征增强**：用LLM生成Embedding。
  - **少样本学习**：冷启动场景排序。
- **案例**：小型LLM（如DistilBERT）用于内容推荐。
- **挑战**：实时性需优化。

### 4.6 多样性与公平性优化
- **趋势**：关注多样性和曝光公平性。
- **进展**：
  - **DPP**：减少相似候选项。
  - **公平性调整**：加权长尾内容。
- **案例**：Spotify音乐推荐。

---

## 5. 总结

### 5.1 常用模型总结
- **传统方法**：规则排序、LR、GBDT、浅层DNN、向量相似度。
- **特点**：轻量化、高效，适合快速筛选。

### 5.2 最新进展总结
- **技术方向**：轻量化深度模型、多任务学习、预计算、自适应、LLM增强、多样性优化。
- **工业应用**：字节跳动、阿里等已广泛应用蒸馏和预计算。
- **研究前沿**：LLM和多样性优化是2023-2024热点，实时性仍是挑战。

---
