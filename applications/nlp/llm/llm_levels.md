# 大模型应用分档

以下是大模型应用的分档表格，从小白应用到训练优化，逐步递进，涵盖不同技术要求和应用场景：

| **档次**         | **描述**                           | **技术要求**                     | **典型应用场景**                   | **用户群体**           |
|-------------------|------------------------------------|----------------------------------|------------------------------------|-------------------------|
| **小白应用**     | 直接使用现成大模型，无需任何调整   | 无技术背景，只需自然语言输入     | 日常问答、文本生成、简单翻译       | 普通用户、非技术人员   |
| **提示工程应用** | 通过设计提示优化模型输出，无代码   | 理解模型逻辑，掌握提示设计技巧   | 专业回答、文案生成、内容总结       | 内容创作者、初级用户   |
| **低代码应用**   | 使用API或工具调用预训练模型        | 基础编程（如API调用），简单配置  | 定制化聊天机器人、数据分析辅助     | 入门开发者、小型团队   |
| **微调应用**     | 用特定数据微调模型，适配任务       | 编程能力（Python等）、数据处理   | 行业专用模型（如法律、医疗问答）   | 中级开发者、专业团队   |
| **推理优化**     | 优化模型部署效率（如速度、资源）   | 模型压缩、推理框架知识           | 实时应用（如边缘设备、智能硬件）   | 工程师、部署专家       |
| **训练优化**     | 从头训练或大幅调整模型架构         | 深度学习知识、大规模计算资源     | 新模型研发、多模态任务             | 高级研究者、大型企业   |

---

## prompt
- In-Context Learning（上下文学习）：通过输入中的上下文直接让模型理解任务。
- Few-Shot Learning（少样本学习）：提供少量示例引导模型。
- Zero-Shot Learning（零样本学习）：无示例，直接靠指令完成任务。

## 检索增强(结合外部知识检索和生成，提升回答的事实性和时效性。)
- RAG
- Knowledge Graph, KG

## 微调
- 全量微调（Full Fine-Tuning）：调整模型全部参数，效果好但资源消耗大。
- 部分微调（Parameter-Efficient Fine-Tuning, PEFT）：如LoRA、Adapter，只调整少量参数，高效且灵活。

## 对齐（让模型输出符合人类价值观、安全性和偏好）
- RLHF

## 蒸馏
- 模型蒸馏（Model Distillation）：大模型压缩到小模型，注重整体性能迁移。
- 知识蒸馏（Knowledge Distillation）：传递特定知识或软标签，优化任务表现。

以上是大模型应用的常用技术


---
## 推理能力
- Chain-of-Thought (CoT)：引导模型逐步推理。
- Self-Consistency：多次生成答案并选择一致性高的结果。
- Autoregressive Enhancement：自我迭代优化输出。


---
## 大模型训练或推理效率优化
- MoE（Mixture of Experts）：动态选择专家子模型，降低计算量。
- 量化（Quantization）：权重转为低精度，减少存储和推理成本。
- 剪枝（Pruning）：移除冗余参数，压缩模型。
- 模型蒸馏（Model Distillation）：大模型压缩到小模型，注重整体性能迁移。


---
## agent
## 多模态

## 说明
1. **层次递进**：从“零技术”到“高阶研发”，技术门槛逐步提高。
2. **新增档次**：加入“低代码应用”作为提示工程和微调之间的过渡。
3. **区分重点**：
   - 提示工程无代码，微调需要代码。
   - 推理优化偏性能，训练优化偏能力。
4. **应用场景**：覆盖从日常使用到专业研发的不同需求。

此表格旨在为不同层次的用户提供清晰的应用路径。
