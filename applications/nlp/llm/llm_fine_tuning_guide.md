# 大模型微调方法指南

## 目录
1. [全参数微调（Full Fine-tuning）](#全参数微调full-fine-tuning)
2. [部分参数微调（Partial Fine-tuning）](#部分参数微调partial-fine-tuning)
7. [知识蒸馏（Knowledge Distillation）](#知识蒸馏knowledge-distillation)
8. [持续学习（Continual Learning）](#持续学习continual-learning)
9. [少样本微调（Few-shot Fine-tuning）](#少样本微调few-shot-fine-tuning)
10. [多任务微调（Multi-task Fine-tuning）](#多任务微调multi-task-fine-tuning)
11. [基于强化学习的微调（RL Fine-tuning）](#基于强化学习的微调rl-fine-tuning)
12. [基于对比学习的微调（Contrastive Fine-tuning）](#基于对比学习的微调contrastive-fine-tuning)
13. [总结](#总结)

---

## 全参数微调（Full Fine-tuning）
- **方法：** 对整个预训练模型的所有参数进行微调。
- **优点：**
  - 模型可以充分适应目标任务。
  - 适合数据量较大的场景。
- **缺点：**
  - 计算成本高，需要大量GPU资源。
  - 容易过拟合，尤其是在数据量较少时。
- **适用场景：** 数据量较大、计算资源充足的任务。

---
## 部分参数微调（Partial Fine-tuning）
### Head-only Fine-tuning（仅微调头部）
- **方法：** 冻结预训练模型的主体（Backbone，如 Transformer 的所有层），仅微调任务特定的头部（Head）。头部通常是一个小型分类器（如线性层或 MLP），接在模型最后一层输出后。
- **优点：**
  - 计算成本较低。
  - 不改变预训练知识，仅适配任务输出。
- **缺点：**
  - 无法调整模型内部表示，效果受限。
- **适用场景：** 数据量较少、计算资源有限的任务。


### 层级微调（layer-wise Fine-tuning）
- **方法：** 只微调模型的某些层（如最后几层），而冻结其他层的参数。
- **优点：**
  - 计算成本较低。
  - 适合数据量较少的场景。
- **缺点：**
  - 可能无法充分利用预训练模型的知识。
- **适用场景：** 数据量较少、计算资源有限的任务。


### 适配器微调（Adapter Fine-tuning）
- **方法：** 在模型的每一层中插入小型适配器模块（Adapter），只微调这些适配器，而冻结原始模型的参数。
- **优点：**
  - 计算成本低，参数效率高。
  - 适合多任务学习。
- **缺点：**
  - 需要设计适配器结构。
- **适用场景：** 多任务学习、资源受限的场景。


### 提示微调（Prompt Tuning）
- **方法：** 通过设计提示词（Prompt）来引导模型生成目标输出，而不直接修改模型参数。
- **优点：**
  - 无需修改模型参数，计算成本低。
  - 适合少样本（Few-shot）或零样本（Zero-shot）学习。
- **缺点：**
  - 提示词设计需要技巧。
- **适用场景：** 少样本或零样本学习任务。


### 前缀微调（Prefix Tuning）
- **方法：** 在输入前添加可学习的“前缀”向量，只微调这些前缀向量，而冻结模型的其他参数。
- **优点：**
  - 参数效率高，计算成本低。
  - 适合生成任务。
- **缺点：**
  - 需要设计前缀结构。
- **适用场景：** 生成任务（如文本生成、对话系统）。


### 低秩适应（LoRA, Low-Rank Adaptation）
- **方法：** 在模型的权重矩阵中引入低秩分解，只微调这些低秩矩阵，而冻结原始权重。
- **优点：**
  - 参数效率高，计算成本低。
  - 适合大规模模型的微调。
- **缺点：**
  - 需要设计低秩分解结构。
- **适用场景：** 大规模模型的轻量级微调。


### BitFit (Bias-only Fine-tuning)
- **方法：** 仅微调模型中的偏置项（Bias Terms），冻结权重矩阵。Transformer 中偏置项包括线性层、LayerNorm 等。
- **优点：**
  - 极轻量，计算成本低。
  - 保留预训练权重，适合小数据集。
- **缺点：**
  - 表达能力有限，效果不如 LoRA 或 Adapter。
- **适用场景：** 小规模任务适配：如分类、NER


![PartFineTuning](https://github.com/nonoyeyouran/MachineLearning/blob/main/applications/recommendation/pictures/MMR.png "MMR")  
---

## 知识蒸馏（Knowledge Distillation）
- **方法：** 使用大模型作为教师模型，训练一个较小的学生模型来模仿教师模型的行为。
- **优点：**
  - 学生模型更轻量，适合部署。
- **缺点：**
  - 需要额外的训练步骤。
- **适用场景：** 模型压缩和部署。

---

## 持续学习（Continual Learning）
- **方法：** 在多个任务上逐步微调模型，同时避免遗忘之前学到的知识。
- **优点：**
  - 适合多任务学习。
- **缺点：**
  - 需要设计防止遗忘的机制。
- **适用场景：** 多任务学习、动态任务环境。

---

## 少样本微调（Few-shot Fine-tuning）
- **方法：** 在少量数据上微调模型，通常结合提示微调或适配器微调。
- **优点：**
  - 适合数据稀缺的场景。
- **缺点：**
  - 模型性能可能受限。
- **适用场景：** 数据稀缺的任务。

---

## 多任务微调（Multi-task Fine-tuning）
- **方法：** 在多个相关任务上同时微调模型，共享部分参数。
- **优点：**
  - 提高模型的泛化能力。
- **缺点：**
  - 需要平衡不同任务的损失。
- **适用场景：** 多任务学习。

---

## 基于强化学习的微调（RL Fine-tuning）
- **方法：** 使用强化学习（如PPO算法）对模型进行微调，优化特定目标（如对话质量、任务完成率）。
- **优点：**
  - 适合优化复杂目标。
- **缺点：**
  - 训练过程复杂，计算成本高。
- **适用场景：** 对话系统、游戏AI等。

---

## 基于对比学习的微调（Contrastive Fine-tuning）
- **方法：** 使用对比学习（Contrastive Learning）方法微调模型，增强模型对相似和不同样本的区分能力。
- **优点：**
  - 提高模型的表示能力。
- **缺点：**
  - 需要设计对比损失函数。
- **适用场景：** 表示学习、语义相似度任务。

---

## 总结
| 方法               | 优点                          | 缺点                          | 适用场景                     |
|--------------------|-------------------------------|-------------------------------|------------------------------|
| 全参数微调         | 充分适应目标任务              | 计算成本高，容易过拟合        | 数据量较大、资源充足的任务   |
| 部分参数微调       | 计算成本低                    | 可能无法充分利用预训练知识    | 数据量较少、资源有限的任务   |
| 适配器微调         | 参数效率高，适合多任务学习    | 需要设计适配器结构            | 多任务学习、资源受限的场景   |
| 提示微调           | 无需修改参数，适合少样本学习  | 提示词设计需要技巧            | 少样本或零样本学习任务       |
| 前缀微调           | 参数效率高，适合生成任务      | 需要设计前缀结构              | 生成任务（如文本生成）       |
| 低秩适应（LoRA）   | 参数效率高，适合大规模模型    | 需要设计低秩分解结构          | 大规模模型的轻量级微调       |
| 知识蒸馏           | 学生模型轻量，适合部署        | 需要额外的训练步骤            | 模型压缩和部署               |
| 持续学习           | 适合多任务学习                | 需要设计防止遗忘的机制        | 多任务学习、动态任务环境     |
| 少样本微调         | 适合数据稀缺的场景            | 模型性能可能受限              | 数据稀缺的任务               |
| 多任务微调         | 提高模型的泛化能力            | 需要平衡不同任务的损失        | 多任务学习                   |
| 基于强化学习的微调 | 适合优化复杂目标              | 训练过程复杂，计算成本高      | 对话系统、游戏AI等           |
| 基于对比学习的微调 | 提高模型的表示能力            | 需要设计对比损失函数          | 表示学习、语义相似度任务     |

---

## 文件信息
- **文件名：** model_fine_tuning_methods.md
- **作者：** DeepSeek-V3
- **版本：** 1.0
- **日期：** 2023年10月
