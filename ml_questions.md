# 机器学习常见问题
---

- [特征编码相关问题](#特征编码相关问题)   
  - [one-hot vs embedding](#onehot-vs-embedding)   
- [连续特征离散化](#连续特征离散化) 
- [定价模型中拟合对比二分类的问题](#定价模型中拟合对比二分类的问题)

---

## 特征编码相关问题
### onehot vs embedding
- **从计算效率看：** one-hot在高维情况下计算效率低，尤其在深度学习网络中；embedding相对维度较低，且数值稠密，计算效率高。  
- **从表征能力看：** one-hot只能表示一种属性，且对这种属性的强度描述只有两种状态；one-hot所在向量空间，每一个特征都是正交的，无法表示更多含义（如NLP中的语义）。embedding是稠密的向量，每个特征表示可以表示多个属性，且每个属性有一个连续的强度表示；特征间的内积可以表征语义相似性；
---

## 连续特征离散化
连续特征离散化从行为上看是在聚合数据，原来属于一个点的数据，现在聚合在一个区间上，带来的一个只管效果就是数据量增加。因此可以带来如下好处：  
1. 聚合数据，使得模式更明显，更易于学习，减少过拟合风险。  
2. 模型更稳定，减少对噪音数据的敏感性。  
3. 模型收敛更快。  
4. 给模型提供了一定的可解释性。  
5. 离散化提供了一种分段线性函数，可以进行非线性建模学习。
---

## 定价模型中拟合对比二分类的问题
**问题描述：** 一个比价场景，需要对比自己产品的价格和对手出价（比如要低于对手出价的一半），有两种方式：一种是对自己的产品学习一个定价模型（回归模型），然后再和对手去比价；另一种是直接学习的二分类的比价模型，即是否低于对手一半，这两种方式如何选择？  
**解析：**  
1. 是否需要一个价格用于分析和解释，如果需要，则用回归模型。  
2. 如果不需要，则考虑数据集大小，分类任务隐式地学习了一个价格预测，然后模型比较两者价格，这里需要一对数据（自己产品出价和对手产品出价），想要覆盖合理数值范围内的所有对数据，需要较大数据集。因此如果数据集比较大，则建议用分类方法，它可以直接学习目标结果（回归还需要一个后续比较过程），数据量大的时候模式明显且对各种模式的覆盖率较高，学习出的模型比较稳定；  
3. 如果数据集比较小，则建议使用回归方法，通过后续人工比价可以覆盖很多比价模式（1v2, 1v3等等）。  
