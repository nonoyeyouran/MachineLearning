# 机器学习常见问题
---

- [特征编码相关问题](#特征编码相关问题)   
  - [one-hot vs embedding](#onehot-vs-embedding)   
- [连续特征离散化](#连续特征离散化) 


---

## 特征编码相关问题
### onehot vs embedding
- 从计算效率看：one-hot在高维情况下计算效率低，尤其在深度学习网络中；embedding相对维度较低，且数值稠密，计算效率高。  
- 从表征能力看：one-hot只能表示一种属性，且对这种属性的强度描述只有两种状态；one-hot所在向量空间，每一个特征都是正交的，无法表示更多含义（如NLP中的语义）。embedding是稠密的向量，每个特征表示可以表示多个属性，且每个属性有一个连续的强度表示；特征间的内积可以表征语义相似性；
---

## 连续特征离散化
连续特征离散化从行为上看是在聚合数据，原来属于一个点的数据，现在聚合在一个区间上，带来的一个只管效果就是数据量增加。因此可以带来如下好处：  
1. 聚合数据，使得模式更明显，更易于学习，减少过拟合风险。  
2. 模型更稳定，减少对噪音数据的敏感性。  
3. 模型收敛更快。  
4. 给模型提供了一定的可解释性。  
5. 离散化提供了一种分段线性函数，可以进行非线性建模学习。  
